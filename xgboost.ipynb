{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9b42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e22ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "hist_mar = pd.read_csv('historical_marathon_dataset.csv')\n",
    "\n",
    "# Convert gender to category\n",
    "hist_mar['gender'] = hist_mar['gender'].astype('category')\n",
    "\n",
    "# Clean up country field\n",
    "hist_mar['country'] = hist_mar['country'].replace({\n",
    "    'Aus': 'Australia',\n",
    "    'Australaia': 'Australia',\n",
    "    'US': 'USA',\n",
    "    'United States': 'USA'\n",
    "})\n",
    "hist_mar['country'] = hist_mar['country'].fillna('Unkown').astype('category')\n",
    "\n",
    "# Clean up shoe_brand\n",
    "hist_mar['shoe_brand'] = hist_mar['shoe_brand'].replace({'Addas': 'Adidas'})\n",
    "hist_mar['shoe_brand'] = hist_mar['shoe_brand'].fillna('Unkown').str.strip()\n",
    "hist_mar['shoe_brand'] = hist_mar['shoe_brand'].astype('category')\n",
    "\n",
    "# Remove negative values in weekly_km\n",
    "hist_mar = hist_mar[hist_mar['weekly_km'] >= 0]\n",
    "\n",
    "# Convert boolean features to bool\n",
    "for col in ['injured_prev_mth', 'injured_prev_qtr', 'injured_prev_hy']:\n",
    "    hist_mar[col] = hist_mar[col].astype(bool)\n",
    "\n",
    "# Load event summary and convert boolean fields\n",
    "event_summary = pd.read_csv('event_summary.csv')\n",
    "for col in ['gel_support', 'stretching_station', 'music_at_start']:\n",
    "    event_summary[col] = event_summary[col].astype(bool)\n",
    "\n",
    "# Merge datasets\n",
    "data = hist_mar.merge(event_summary, on='year', how='left')\n",
    "\n",
    "# Create needed_med flag\n",
    "data['needed_med'] = ~data['medical_km_bin'].isna()\n",
    "hist_mar['needed_med'] = ~hist_mar['medical_km_bin'].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a54896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>weekly_km</th>\n",
       "      <th>country</th>\n",
       "      <th>shoe_brand</th>\n",
       "      <th>marathons_xp</th>\n",
       "      <th>personal_best</th>\n",
       "      <th>...</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>elevation_gain</th>\n",
       "      <th>hydration_stations</th>\n",
       "      <th>gel_support</th>\n",
       "      <th>stretching_station</th>\n",
       "      <th>music_at_start</th>\n",
       "      <th>toilet_stations</th>\n",
       "      <th>crowding_density</th>\n",
       "      <th>newsletter_registration</th>\n",
       "      <th>needed_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>169.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>38</td>\n",
       "      <td>USA</td>\n",
       "      <td>Asics</td>\n",
       "      <td>2</td>\n",
       "      <td>271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>705</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>172.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>102</td>\n",
       "      <td>USA</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>3</td>\n",
       "      <td>278.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>155.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>68</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Saucony</td>\n",
       "      <td>1</td>\n",
       "      <td>323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>54</td>\n",
       "      <td>Female</td>\n",
       "      <td>195.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>3</td>\n",
       "      <td>426.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>170.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>705</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  age  gender  height  weight  weekly_km    country shoe_brand  \\\n",
       "0  2004.0   36  Female   169.0    75.0         38        USA      Asics   \n",
       "1  2004.0   31  Female   172.0    71.0        102        USA     Brooks   \n",
       "2  2004.0   32    Male   155.0    59.0         68    Germany    Saucony   \n",
       "3  2004.0   54  Female   195.0    88.0         80  Australia     Adidas   \n",
       "4  2004.0   27  Female   170.0    75.0         37        USA     Adidas   \n",
       "\n",
       "   marathons_xp  personal_best  ...  rainfall  elevation_gain  \\\n",
       "0             2          271.0  ...      1.91             213   \n",
       "1             3          278.0  ...      1.91             213   \n",
       "2             1          323.0  ...      1.91             213   \n",
       "3             3          426.0  ...      1.91             213   \n",
       "4             2          322.0  ...      1.91             213   \n",
       "\n",
       "   hydration_stations  gel_support  stretching_station  music_at_start  \\\n",
       "0                  13        False               False           False   \n",
       "1                  13        False               False           False   \n",
       "2                  13        False               False           False   \n",
       "3                  13        False               False           False   \n",
       "4                  13        False               False           False   \n",
       "\n",
       "   toilet_stations  crowding_density  newsletter_registration  needed_med  \n",
       "0               12              0.44                      705        True  \n",
       "1               12              0.44                      705       False  \n",
       "2               12              0.44                      705       False  \n",
       "3               12              0.44                      705       False  \n",
       "4               12              0.44                      705       False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebad619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>weekly_km</th>\n",
       "      <th>marathons_xp</th>\n",
       "      <th>personal_best</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>medical_km_bin</th>\n",
       "      <th>temp_10am</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>elevation_gain</th>\n",
       "      <th>hydration_stations</th>\n",
       "      <th>toilet_stations</th>\n",
       "      <th>crowding_density</th>\n",
       "      <th>newsletter_registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62848.000000</td>\n",
       "      <td>62821.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>58615.000000</td>\n",
       "      <td>62031.000000</td>\n",
       "      <td>10481.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2014.249230</td>\n",
       "      <td>35.989627</td>\n",
       "      <td>167.307742</td>\n",
       "      <td>72.711768</td>\n",
       "      <td>49.967053</td>\n",
       "      <td>2.720985</td>\n",
       "      <td>312.359447</td>\n",
       "      <td>350.464719</td>\n",
       "      <td>24.817861</td>\n",
       "      <td>21.476759</td>\n",
       "      <td>64.357156</td>\n",
       "      <td>2.659061</td>\n",
       "      <td>251.998491</td>\n",
       "      <td>13.928594</td>\n",
       "      <td>7.976315</td>\n",
       "      <td>0.559518</td>\n",
       "      <td>725.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.061157</td>\n",
       "      <td>9.066241</td>\n",
       "      <td>11.857175</td>\n",
       "      <td>50.169155</td>\n",
       "      <td>22.423361</td>\n",
       "      <td>1.628177</td>\n",
       "      <td>48.358202</td>\n",
       "      <td>40.618835</td>\n",
       "      <td>8.625838</td>\n",
       "      <td>5.559836</td>\n",
       "      <td>7.630199</td>\n",
       "      <td>1.335630</td>\n",
       "      <td>27.922830</td>\n",
       "      <td>2.433790</td>\n",
       "      <td>2.549221</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>82.923920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>573.000000</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year           age        height        weight     weekly_km  \\\n",
       "count  62950.000000  62950.000000  62848.000000  62821.000000  62950.000000   \n",
       "mean    2014.249230     35.989627    167.307742     72.711768     49.967053   \n",
       "std        6.061157      9.066241     11.857175     50.169155     22.423361   \n",
       "min     2004.000000     18.000000    126.000000     45.000000      3.000000   \n",
       "25%     2009.000000     29.000000    159.000000     64.000000     34.000000   \n",
       "50%     2014.000000     36.000000    167.000000     70.000000     47.000000   \n",
       "75%     2019.500000     42.000000    175.000000     76.000000     63.000000   \n",
       "max     2024.500000     70.000000    216.000000    999.000000    217.000000   \n",
       "\n",
       "       marathons_xp  personal_best   finish_time  medical_km_bin  \\\n",
       "count  62950.000000   58615.000000  62031.000000    10481.000000   \n",
       "mean       2.720985     312.359447    350.464719       24.817861   \n",
       "std        1.628177      48.358202     40.618835        8.625838   \n",
       "min        0.000000     130.000000    190.000000        0.000000   \n",
       "25%        2.000000     280.000000    323.000000       18.000000   \n",
       "50%        3.000000     309.000000    352.000000       26.000000   \n",
       "75%        4.000000     342.000000    379.000000       32.000000   \n",
       "max       11.000000     573.000000    449.000000       42.000000   \n",
       "\n",
       "          temp_10am      humidity      rainfall  elevation_gain  \\\n",
       "count  62950.000000  62950.000000  62950.000000    62950.000000   \n",
       "mean      21.476759     64.357156      2.659061      251.998491   \n",
       "std        5.559836      7.630199      1.335630       27.922830   \n",
       "min       12.000000     51.000000      0.100000      201.000000   \n",
       "25%       16.000000     58.000000      1.540000      230.000000   \n",
       "50%       22.000000     65.000000      2.400000      253.000000   \n",
       "75%       26.000000     71.000000      3.880000      272.000000   \n",
       "max       30.000000     79.000000      4.980000      300.000000   \n",
       "\n",
       "       hydration_stations  toilet_stations  crowding_density  \\\n",
       "count        62950.000000     62950.000000      62950.000000   \n",
       "mean            13.928594         7.976315          0.559518   \n",
       "std              2.433790         2.549221          0.113526   \n",
       "min             10.000000         4.000000          0.400000   \n",
       "25%             12.000000         5.000000          0.460000   \n",
       "50%             14.000000         8.000000          0.540000   \n",
       "75%             16.000000        10.000000          0.640000   \n",
       "max             18.000000        12.000000          0.790000   \n",
       "\n",
       "       newsletter_registration  \n",
       "count             62950.000000  \n",
       "mean                725.007069  \n",
       "std                  82.923920  \n",
       "min                 600.000000  \n",
       "25%                 660.000000  \n",
       "50%                 720.000000  \n",
       "75%                 765.000000  \n",
       "max                 900.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a774071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4283/1768508953.py:121: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['weekly_km_percentile'] = class_data.groupby('gender')['weekly_km'].transform(percent_rank)\n",
      "/tmp/ipykernel_4283/1768508953.py:122: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['age_percentile'] = class_data.groupby('gender')['age'].transform(percent_rank)\n",
      "/tmp/ipykernel_4283/1768508953.py:123: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['weight_percentile'] = class_data.groupby('gender')['weight'].transform(percent_rank)\n",
      "/tmp/ipykernel_4283/1768508953.py:124: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['bmi_percentile'] = class_data.groupby('gender')['bmi'].transform(percent_rank)\n",
      "/tmp/ipykernel_4283/1768508953.py:125: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['experience_percentile'] = class_data.groupby('gender')['marathons_xp'].transform(percent_rank)\n",
      "/tmp/ipykernel_4283/1768508953.py:126: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_data['pb_percentile'] = class_data.groupby('gender')['personal_best'].transform(lambda x: percent_rank(-x))\n"
     ]
    }
   ],
   "source": [
    "# Copy data and drop unneeded columns\n",
    "class_data = data.copy()\n",
    "class_data.drop(columns=['medical_km_bin', 'finish_time'], inplace=True)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "class_data.dropna(inplace=True)\n",
    "\n",
    "# === PHYSICAL PERFORMANCE FEATURES ===\n",
    "class_data['bmi'] = class_data['weight'] / (class_data['height'] / 100) ** 2\n",
    "class_data['training_intensity'] = class_data['weekly_km'] / class_data['age']\n",
    "class_data['experience_per_age'] = class_data['marathons_xp'] / class_data['age']\n",
    "\n",
    "# === INJURY HISTORY PATTERNS ===\n",
    "class_data['injury_cascade'] = ((class_data['injured_prev_mth']) & (class_data['injured_prev_qtr'])).astype(int)\n",
    "class_data['chronic_injury_pattern'] = ((class_data['injured_prev_mth']) & \n",
    "                                         (class_data['injured_prev_qtr']) & \n",
    "                                         (class_data['injured_prev_hy'])).astype(int)\n",
    "class_data['recent_only_injury'] = ((class_data['injured_prev_mth']) & \n",
    "                                    (~class_data['injured_prev_qtr']) & \n",
    "                                    (~class_data['injured_prev_hy'])).astype(int)\n",
    "class_data['worsening_injury'] = ((class_data['injured_prev_mth']) & \n",
    "                                  (~class_data['injured_prev_qtr'])).astype(int)\n",
    "class_data['improving_injury'] = ((~class_data['injured_prev_mth']) & \n",
    "                                  (class_data['injured_prev_qtr'])).astype(int)\n",
    "class_data['injury_free_recent'] = ((~class_data['injured_prev_mth']) & \n",
    "                                    (~class_data['injured_prev_qtr'])).astype(int)\n",
    "\n",
    "# === ENVIRONMENTAL STRESS FACTORS ===\n",
    "class_data['heat_humidity_interaction'] = class_data['temp_10am'] * class_data['humidity'] / 100\n",
    "class_data['temp_humidity_ratio'] = np.where(class_data['humidity'] > 0,\n",
    "                                             class_data['temp_10am'] / class_data['humidity'],\n",
    "                                             class_data['temp_10am'])\n",
    "\n",
    "class_data['extreme_heat'] = ((class_data['temp_10am'] > 26) & (class_data['humidity'] > 71)).astype(int)\n",
    "class_data['extreme_weather'] = ((class_data['temp_10am'] > 30) |\n",
    "                                 (class_data['humidity'] > 80) |\n",
    "                                 (class_data['rainfall'] > 3.8)).astype(int)\n",
    "class_data['high_temp_low_humidity'] = ((class_data['temp_10am'] > 26) &\n",
    "                                        (class_data['humidity'] < 58)).astype(int)\n",
    "\n",
    "# === RACE SUPPORT QUALITY ===\n",
    "class_data['hydration_per_crowd'] = class_data['hydration_stations'] / class_data['crowding_density']\n",
    "class_data['toilet_per_crowd'] = class_data['toilet_stations'] / class_data['crowding_density']\n",
    "class_data['has_performance_support'] = ((class_data['gel_support']) | \n",
    "                                         (class_data['stretching_station'])).astype(int)\n",
    "class_data['full_support_package'] = ((class_data['gel_support']) & \n",
    "                                      (class_data['stretching_station'])).astype(int)\n",
    "class_data['minimal_hydration'] = (class_data['hydration_stations'] <= 2).astype(int)\n",
    "class_data['inadequate_facilities'] = (class_data['toilet_stations'] <= 1).astype(int)\n",
    "\n",
    "# For median-based indicators\n",
    "hydration_median = class_data['hydration_stations'].median()\n",
    "crowding_median = class_data['crowding_density'].median()\n",
    "\n",
    "class_data['high_crowd_low_hydration'] = ((class_data['crowding_density'] > crowding_median) & \n",
    "                                          (class_data['hydration_stations'] < hydration_median)).astype(int)\n",
    "\n",
    "class_data['support_mismatch'] = ((class_data['hydration_stations'] < 3) & \n",
    "                                  (class_data['gel_support'])).astype(int)\n",
    "\n",
    "# === DEMOGRAPHIC INTERACTIONS ===\n",
    "class_data['age_experience_mismatch'] = class_data['age'] - 2 * class_data['marathons_xp']\n",
    "\n",
    "# === CATEGORICAL ENGINEERING ===\n",
    "def age_group(age):\n",
    "    if age < 30: return \"Under_30\"\n",
    "    elif age < 40: return \"30s\"\n",
    "    elif age < 50: return \"40s\"\n",
    "    elif age < 60: return \"50s\"\n",
    "    else: return \"60_plus\"\n",
    "\n",
    "class_data['age_group'] = class_data['age'].apply(age_group)\n",
    "\n",
    "class_data['training_level'] = pd.cut(\n",
    "    class_data['weekly_km'],\n",
    "    bins=[-np.inf, 34, 63, np.inf],\n",
    "    labels=[\"Low\", \"Medium\", \"High\"]\n",
    ")\n",
    "\n",
    "def experience_level(x):\n",
    "    if x == 0: return \"First_timer\"\n",
    "    elif x < 3: return \"Novice\"\n",
    "    elif x < 5: return \"Intermediate\"\n",
    "    else: return \"Expert\"\n",
    "\n",
    "class_data['experience_level'] = class_data['marathons_xp'].apply(experience_level)\n",
    "\n",
    "def pb_tier(pb):\n",
    "    if pb < 180: return \"Elite\"\n",
    "    elif pb < 240: return \"Fast\"\n",
    "    elif pb < 300: return \"Average\"\n",
    "    else: return \"Recreational\"\n",
    "\n",
    "class_data['pb_tier'] = class_data['personal_best'].apply(pb_tier)\n",
    "\n",
    "# === HIGH-RISK INDICATORS ===\n",
    "class_data['high_risk_age'] = (class_data['age'] > 50).astype(int)\n",
    "class_data['overexertion_risk'] = (class_data['weekly_km'] > (class_data['age'] * 2)).astype(int)\n",
    "class_data['inexperienced_ambitious'] = ((class_data['marathons_xp'] < 3) &\n",
    "                                         (class_data['personal_best'] < 240)).astype(int)\n",
    "\n",
    "# === INTERACTION TERMS ===\n",
    "class_data['age_recent_injury'] = class_data['age'] * class_data['injured_prev_mth']\n",
    "\n",
    "class_data['poor_support_harsh_conditions'] = ((class_data['hydration_stations'] < hydration_median).astype(int) *\n",
    "                                               (class_data['temp_10am'] + class_data['humidity']))\n",
    "\n",
    "# === CUMULATIVE RISK SCORE ===\n",
    "class_data['cumulative_risk_score'] = ((class_data['injured_prev_mth'] * 3 +\n",
    "                                        class_data['injured_prev_qtr'] * 2 +\n",
    "                                        class_data['injured_prev_hy']) *\n",
    "                                       (class_data['temp_10am'] + class_data['humidity']) / 100)\n",
    "\n",
    "# === PERCENTILE RANKS WITHIN GENDER ===\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def percent_rank(series):\n",
    "    return (rankdata(series, method='min') - 1) / (len(series) - 1)\n",
    "\n",
    "# Apply percentile ranks within gender using transform\n",
    "class_data['weekly_km_percentile'] = class_data.groupby('gender')['weekly_km'].transform(percent_rank)\n",
    "class_data['age_percentile'] = class_data.groupby('gender')['age'].transform(percent_rank)\n",
    "class_data['weight_percentile'] = class_data.groupby('gender')['weight'].transform(percent_rank)\n",
    "class_data['bmi_percentile'] = class_data.groupby('gender')['bmi'].transform(percent_rank)\n",
    "class_data['experience_percentile'] = class_data.groupby('gender')['marathons_xp'].transform(percent_rank)\n",
    "class_data['pb_percentile'] = class_data.groupby('gender')['personal_best'].transform(lambda x: percent_rank(-x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70dd3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "\n",
    "def fbeta_eval(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_pred = np.argmax(predt, axis=1)\n",
    "\n",
    "    # BETA VALUE\n",
    "    fbeta = fbeta_score(y_true, y_pred, beta=10)\n",
    "    return 'fbeta_eval', fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd5cad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import create_study, logging\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "\n",
    "# number of jobs for optimisation\n",
    "N_JOBS = 1\n",
    "\n",
    "# The following Optuna Optimisation call is heavily insprired by JP (@para24) on Kaggle, see:\n",
    "# https://www.kaggle.com/code/para24/xgboost-stepwise-tuning-using-optuna/notebook#7.-Stepwise-Hyperparameter-Tuning\n",
    "\n",
    "def _objective(trial, X, y, num_classes, group, score, params=dict()):\n",
    "    \"\"\"\n",
    "    `X` and `y` MUST be pd.DataFrames - NOT `xgb.DMatrix`.  \n",
    "    \"\"\"\n",
    "    dtrain = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
    "\n",
    "\n",
    "    if group == '1':\n",
    "        params['max_depth'] = trial.suggest_int('max_depth', 2, 30)\n",
    "        params['min_child_weight'] = trial.suggest_loguniform('min_child_weight', 1e-10, 1e10)\n",
    "    \n",
    "    if group == '2':\n",
    "        params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n",
    "        params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0, 1)\n",
    "\n",
    "    if group == '3':\n",
    "        params['num_boost_round'] = trial.suggest_int('num_boost_round', 100, 600)\n",
    "        params['learning_rate'] = trial.suggest_uniform('learning_rate', 0.005, 0.1)\n",
    "\n",
    "    if group == '4':\n",
    "        params['gamma'] = trial.suggest_loguniform('gamma', 1e-3, 19)\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, 'test-' + score.__name__)\n",
    "\n",
    "    xgb_params = params.copy()\n",
    "    del xgb_params['num_boost_round']\n",
    "\n",
    "    cv_scores = xgb.cv(xgb_params, dtrain, nfold=5,\n",
    "                       stratified=True,\n",
    "                       feval=score,\n",
    "                       num_boost_round=params['num_boost_round'],\n",
    "                       early_stopping_rounds=10,\n",
    "                       callbacks=[pruning_callback])\n",
    "    \n",
    "    return cv_scores['test-' + score.__name__ + '-mean'].values[-1]\n",
    "\n",
    "def _execute_optimisation(X_train, y_train, num_classes, study_name, group, score, trials, db_url:str, params=dict(), direction='maximize', n_jobs=1):\n",
    "    ## use pruner to skip trials that aren't doing so well\n",
    "    pruner = MedianPruner(n_warmup_steps=20)\n",
    "\n",
    "    ## use sampler to use past results from db\n",
    "    sampler = TPESampler(n_startup_trials=20, multivariate=True, warn_independent_sampling=False)\n",
    "\n",
    "    study = create_study(\n",
    "        direction=direction,\n",
    "        study_name=study_name,\n",
    "        storage=f'sqlite:///{db_url}',\n",
    "        load_if_exists=True,\n",
    "        pruner=pruner,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: _objective(trial, X_train, y_train, num_classes, group, score, params),\n",
    "        n_trials=trials,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    print('STUDY NAME: ', study_name)\n",
    "    print('-------------------------------------------------------')\n",
    "    print('EVALUATION METRIC: ', score.__name__)\n",
    "    print('-------------------------------------------------------')\n",
    "    print('BEST CV SCORE: ', study.best_value)\n",
    "    print('-------------------------------------------------------')\n",
    "    print(f'OPTIMAL GROUP - {group} PARAMS: ', study.best_params)\n",
    "    print('-------------------------------------------------------')\n",
    "    print('BEST TRIAL', study.best_trial)\n",
    "    print('-------------------------------------------------------')\n",
    "\n",
    "    updated_params = params.copy()\n",
    "    updated_params.update(study.best_params)\n",
    "\n",
    "    return updated_params\n",
    "\n",
    "def stepwise_optimisation(X_train: pd.DataFrame, y_train: pd.DataFrame, num_classes: int, eval_metric: callable, db_url: str, n_jobs=1, trials=9) -> dict:\n",
    "    \"\"\"\n",
    "    Execute stepwise optimisation to find optimal CV parameters for XGBoost given the train set. \n",
    "\n",
    "    params:\n",
    "        `X_train` (pd.DataFrame) - training set - NOT A `xgb.DMatrix` object\n",
    "\n",
    "        `y_train` (pd.DataFrame) - as above\n",
    "\n",
    "        `num_classes` (int) - the number of classes used to categorise returns\n",
    "\n",
    "        `eval_metric` (callable) - evaluation metric to be used in optimisation. See `eval_metrics.py`\n",
    "\n",
    "        `trials` - number of trials to do for `optimize`\n",
    "\n",
    "    returns:\n",
    "        a dictionary containing optimal parameters\n",
    "    \"\"\"\n",
    "    final_params = dict()\n",
    "\n",
    "    # initial learning params\n",
    "    final_params['num_boost_round'] = 200\n",
    "    final_params['learning_rate'] = 0.01\n",
    "    final_params['num_class'] = num_classes\n",
    "    final_params['objective'] = 'multi:softprob'\n",
    "\n",
    "    # use gpu\n",
    "    #final_params['tree_method'] = 'hist'\n",
    "    #final_params['device'] = 'cuda'\n",
    "\n",
    "\n",
    "    for g in ['1', '2', '3', '4']:\n",
    "        print(f'====== Optimising Group {g} ======')\n",
    "        update_params = _execute_optimisation(\n",
    "            X_train, y_train, num_classes, 'xgboost', g, eval_metric, trials, db_url, params=final_params, direction='maximize', n_jobs=n_jobs\n",
    "        )\n",
    "        final_params.update(update_params)\n",
    "        print(f'Params after updating group {g}: ', final_params)\n",
    "        print('\\n\\n')\n",
    "\n",
    "    print(f'====== Final Optimal Parameters ======')\n",
    "    print(final_params)\n",
    "\n",
    "    return final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "158437ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = class_data.drop(['year', 'needed_med'], axis=1).copy()\n",
    "y = class_data['needed_med'].copy()\n",
    "\n",
    "categorical_cols = ['gender', 'country', 'shoe_brand', 'age_group', 'training_level', 'experience_level', 'pb_tier']\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98363362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Optimising Group 1 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.08057560000000001\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 1 PARAMS:  {'max_depth': 27, 'min_child_weight': 0.696828678458152}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=58, state=1, values=[0.08057560000000001], datetime_start=datetime.datetime(2025, 7, 7, 23, 50, 27, 760310), datetime_complete=datetime.datetime(2025, 7, 7, 23, 51, 23, 788951), params={'max_depth': 27, 'min_child_weight': 0.696828678458152}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.18137699999999998, 1: 0.19500579999999998, 2: 0.1956422, 3: 0.1918806, 4: 0.1899226, 5: 0.1900556, 6: 0.1869188, 7: 0.18392060000000002, 8: 0.17777420000000002, 9: 0.17503059999999998, 10: 0.1721606, 11: 0.17230360000000003, 12: 0.16785260000000002, 13: 0.16536240000000002, 14: 0.1608962, 15: 0.1563096, 16: 0.155399, 17: 0.153964, 18: 0.15304840000000003, 19: 0.1508208, 20: 0.15056, 21: 0.149253, 22: 0.1466254, 23: 0.147028, 24: 0.14479199999999998, 25: 0.143876, 26: 0.14309080000000002, 27: 0.14177940000000003, 28: 0.1401986, 29: 0.1399448, 30: 0.13810660000000002, 31: 0.13666240000000002, 32: 0.1354844, 33: 0.1339054, 34: 0.1302158, 35: 0.13022019999999998, 36: 0.127982, 37: 0.12693340000000003, 38: 0.1254906, 39: 0.12311679999999998, 40: 0.12272279999999999, 41: 0.12035119999999999, 42: 0.11956359999999999, 43: 0.11851039999999999, 44: 0.1174582, 45: 0.11587699999999998, 46: 0.1146906, 47: 0.1135062, 48: 0.1123186, 49: 0.1119278, 50: 0.11140019999999999, 51: 0.1098214, 52: 0.10942700000000001, 53: 0.107581, 54: 0.10771660000000001, 55: 0.1066622, 56: 0.1053434, 57: 0.1049468, 58: 0.104288, 59: 0.1028354, 60: 0.1025738, 61: 0.10231279999999998, 62: 0.1021832, 63: 0.102581, 64: 0.10165900000000001, 65: 0.10007379999999999, 66: 0.0998124, 67: 0.0988896, 68: 0.0992892, 69: 0.098498, 70: 0.0971756, 71: 0.0966482, 72: 0.0961206, 73: 0.09572639999999999, 74: 0.0951986, 75: 0.093876, 76: 0.0941416, 77: 0.0933504, 78: 0.0937484, 79: 0.0933552, 80: 0.09401820000000001, 81: 0.09335940000000001, 82: 0.0926984, 83: 0.0921724, 84: 0.09230659999999999, 85: 0.09138199999999999, 86: 0.09032480000000001, 87: 0.0901948, 88: 0.08966719999999999, 89: 0.0904628, 90: 0.08966959999999999, 91: 0.08900920000000001, 92: 0.0882152, 93: 0.088216, 94: 0.0880856, 95: 0.08769020000000001, 96: 0.0874258, 97: 0.08729659999999999, 98: 0.0870344, 99: 0.08716719999999999, 100: 0.08677140000000001, 101: 0.0863758, 102: 0.0863766, 103: 0.08584739999999999, 104: 0.0857164, 105: 0.08439379999999999, 106: 0.0837332, 107: 0.0841314, 108: 0.0840002, 109: 0.0840024, 110: 0.083606, 111: 0.084136, 112: 0.0842694, 113: 0.08479980000000001, 114: 0.0840066, 115: 0.0842732, 116: 0.0833472, 117: 0.08281780000000001, 118: 0.08202519999999999, 119: 0.082025, 120: 0.0818942, 121: 0.08163000000000001, 122: 0.0818962, 123: 0.0816322, 124: 0.0813692, 125: 0.081634, 126: 0.08057560000000001, 127: 0.0812388, 128: 0.0811072, 129: 0.0811072, 130: 0.080711, 131: 0.08097639999999999, 132: 0.0805794, 133: 0.0812422, 134: 0.08097839999999999, 135: 0.08150779999999999}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=59, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 1:  {'num_boost_round': 200, 'learning_rate': 0.01, 'num_class': 2, 'objective': 'multi:softprob', 'max_depth': 27, 'min_child_weight': 0.696828678458152}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 2 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.08057560000000001\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 2 PARAMS:  {'max_depth': 27, 'min_child_weight': 0.696828678458152}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=58, state=1, values=[0.08057560000000001], datetime_start=datetime.datetime(2025, 7, 7, 23, 50, 27, 760310), datetime_complete=datetime.datetime(2025, 7, 7, 23, 51, 23, 788951), params={'max_depth': 27, 'min_child_weight': 0.696828678458152}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.18137699999999998, 1: 0.19500579999999998, 2: 0.1956422, 3: 0.1918806, 4: 0.1899226, 5: 0.1900556, 6: 0.1869188, 7: 0.18392060000000002, 8: 0.17777420000000002, 9: 0.17503059999999998, 10: 0.1721606, 11: 0.17230360000000003, 12: 0.16785260000000002, 13: 0.16536240000000002, 14: 0.1608962, 15: 0.1563096, 16: 0.155399, 17: 0.153964, 18: 0.15304840000000003, 19: 0.1508208, 20: 0.15056, 21: 0.149253, 22: 0.1466254, 23: 0.147028, 24: 0.14479199999999998, 25: 0.143876, 26: 0.14309080000000002, 27: 0.14177940000000003, 28: 0.1401986, 29: 0.1399448, 30: 0.13810660000000002, 31: 0.13666240000000002, 32: 0.1354844, 33: 0.1339054, 34: 0.1302158, 35: 0.13022019999999998, 36: 0.127982, 37: 0.12693340000000003, 38: 0.1254906, 39: 0.12311679999999998, 40: 0.12272279999999999, 41: 0.12035119999999999, 42: 0.11956359999999999, 43: 0.11851039999999999, 44: 0.1174582, 45: 0.11587699999999998, 46: 0.1146906, 47: 0.1135062, 48: 0.1123186, 49: 0.1119278, 50: 0.11140019999999999, 51: 0.1098214, 52: 0.10942700000000001, 53: 0.107581, 54: 0.10771660000000001, 55: 0.1066622, 56: 0.1053434, 57: 0.1049468, 58: 0.104288, 59: 0.1028354, 60: 0.1025738, 61: 0.10231279999999998, 62: 0.1021832, 63: 0.102581, 64: 0.10165900000000001, 65: 0.10007379999999999, 66: 0.0998124, 67: 0.0988896, 68: 0.0992892, 69: 0.098498, 70: 0.0971756, 71: 0.0966482, 72: 0.0961206, 73: 0.09572639999999999, 74: 0.0951986, 75: 0.093876, 76: 0.0941416, 77: 0.0933504, 78: 0.0937484, 79: 0.0933552, 80: 0.09401820000000001, 81: 0.09335940000000001, 82: 0.0926984, 83: 0.0921724, 84: 0.09230659999999999, 85: 0.09138199999999999, 86: 0.09032480000000001, 87: 0.0901948, 88: 0.08966719999999999, 89: 0.0904628, 90: 0.08966959999999999, 91: 0.08900920000000001, 92: 0.0882152, 93: 0.088216, 94: 0.0880856, 95: 0.08769020000000001, 96: 0.0874258, 97: 0.08729659999999999, 98: 0.0870344, 99: 0.08716719999999999, 100: 0.08677140000000001, 101: 0.0863758, 102: 0.0863766, 103: 0.08584739999999999, 104: 0.0857164, 105: 0.08439379999999999, 106: 0.0837332, 107: 0.0841314, 108: 0.0840002, 109: 0.0840024, 110: 0.083606, 111: 0.084136, 112: 0.0842694, 113: 0.08479980000000001, 114: 0.0840066, 115: 0.0842732, 116: 0.0833472, 117: 0.08281780000000001, 118: 0.08202519999999999, 119: 0.082025, 120: 0.0818942, 121: 0.08163000000000001, 122: 0.0818962, 123: 0.0816322, 124: 0.0813692, 125: 0.081634, 126: 0.08057560000000001, 127: 0.0812388, 128: 0.0811072, 129: 0.0811072, 130: 0.080711, 131: 0.08097639999999999, 132: 0.0805794, 133: 0.0812422, 134: 0.08097839999999999, 135: 0.08150779999999999}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=59, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 2:  {'num_boost_round': 200, 'learning_rate': 0.01, 'num_class': 2, 'objective': 'multi:softprob', 'max_depth': 27, 'min_child_weight': 0.696828678458152, 'subsample': 0.9790743055545253, 'colsample_bytree': 0.7195508901942145}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 3 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.08057560000000001\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 3 PARAMS:  {'max_depth': 27, 'min_child_weight': 0.696828678458152}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=58, state=1, values=[0.08057560000000001], datetime_start=datetime.datetime(2025, 7, 7, 23, 50, 27, 760310), datetime_complete=datetime.datetime(2025, 7, 7, 23, 51, 23, 788951), params={'max_depth': 27, 'min_child_weight': 0.696828678458152}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.18137699999999998, 1: 0.19500579999999998, 2: 0.1956422, 3: 0.1918806, 4: 0.1899226, 5: 0.1900556, 6: 0.1869188, 7: 0.18392060000000002, 8: 0.17777420000000002, 9: 0.17503059999999998, 10: 0.1721606, 11: 0.17230360000000003, 12: 0.16785260000000002, 13: 0.16536240000000002, 14: 0.1608962, 15: 0.1563096, 16: 0.155399, 17: 0.153964, 18: 0.15304840000000003, 19: 0.1508208, 20: 0.15056, 21: 0.149253, 22: 0.1466254, 23: 0.147028, 24: 0.14479199999999998, 25: 0.143876, 26: 0.14309080000000002, 27: 0.14177940000000003, 28: 0.1401986, 29: 0.1399448, 30: 0.13810660000000002, 31: 0.13666240000000002, 32: 0.1354844, 33: 0.1339054, 34: 0.1302158, 35: 0.13022019999999998, 36: 0.127982, 37: 0.12693340000000003, 38: 0.1254906, 39: 0.12311679999999998, 40: 0.12272279999999999, 41: 0.12035119999999999, 42: 0.11956359999999999, 43: 0.11851039999999999, 44: 0.1174582, 45: 0.11587699999999998, 46: 0.1146906, 47: 0.1135062, 48: 0.1123186, 49: 0.1119278, 50: 0.11140019999999999, 51: 0.1098214, 52: 0.10942700000000001, 53: 0.107581, 54: 0.10771660000000001, 55: 0.1066622, 56: 0.1053434, 57: 0.1049468, 58: 0.104288, 59: 0.1028354, 60: 0.1025738, 61: 0.10231279999999998, 62: 0.1021832, 63: 0.102581, 64: 0.10165900000000001, 65: 0.10007379999999999, 66: 0.0998124, 67: 0.0988896, 68: 0.0992892, 69: 0.098498, 70: 0.0971756, 71: 0.0966482, 72: 0.0961206, 73: 0.09572639999999999, 74: 0.0951986, 75: 0.093876, 76: 0.0941416, 77: 0.0933504, 78: 0.0937484, 79: 0.0933552, 80: 0.09401820000000001, 81: 0.09335940000000001, 82: 0.0926984, 83: 0.0921724, 84: 0.09230659999999999, 85: 0.09138199999999999, 86: 0.09032480000000001, 87: 0.0901948, 88: 0.08966719999999999, 89: 0.0904628, 90: 0.08966959999999999, 91: 0.08900920000000001, 92: 0.0882152, 93: 0.088216, 94: 0.0880856, 95: 0.08769020000000001, 96: 0.0874258, 97: 0.08729659999999999, 98: 0.0870344, 99: 0.08716719999999999, 100: 0.08677140000000001, 101: 0.0863758, 102: 0.0863766, 103: 0.08584739999999999, 104: 0.0857164, 105: 0.08439379999999999, 106: 0.0837332, 107: 0.0841314, 108: 0.0840002, 109: 0.0840024, 110: 0.083606, 111: 0.084136, 112: 0.0842694, 113: 0.08479980000000001, 114: 0.0840066, 115: 0.0842732, 116: 0.0833472, 117: 0.08281780000000001, 118: 0.08202519999999999, 119: 0.082025, 120: 0.0818942, 121: 0.08163000000000001, 122: 0.0818962, 123: 0.0816322, 124: 0.0813692, 125: 0.081634, 126: 0.08057560000000001, 127: 0.0812388, 128: 0.0811072, 129: 0.0811072, 130: 0.080711, 131: 0.08097639999999999, 132: 0.0805794, 133: 0.0812422, 134: 0.08097839999999999, 135: 0.08150779999999999}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=59, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 3:  {'num_boost_round': 599, 'learning_rate': 0.09995848838749884, 'num_class': 2, 'objective': 'multi:softprob', 'max_depth': 27, 'min_child_weight': 0.696828678458152, 'subsample': 0.9790743055545253, 'colsample_bytree': 0.7195508901942145}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 4 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.08057560000000001\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 4 PARAMS:  {'max_depth': 27, 'min_child_weight': 0.696828678458152}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=58, state=1, values=[0.08057560000000001], datetime_start=datetime.datetime(2025, 7, 7, 23, 50, 27, 760310), datetime_complete=datetime.datetime(2025, 7, 7, 23, 51, 23, 788951), params={'max_depth': 27, 'min_child_weight': 0.696828678458152}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.18137699999999998, 1: 0.19500579999999998, 2: 0.1956422, 3: 0.1918806, 4: 0.1899226, 5: 0.1900556, 6: 0.1869188, 7: 0.18392060000000002, 8: 0.17777420000000002, 9: 0.17503059999999998, 10: 0.1721606, 11: 0.17230360000000003, 12: 0.16785260000000002, 13: 0.16536240000000002, 14: 0.1608962, 15: 0.1563096, 16: 0.155399, 17: 0.153964, 18: 0.15304840000000003, 19: 0.1508208, 20: 0.15056, 21: 0.149253, 22: 0.1466254, 23: 0.147028, 24: 0.14479199999999998, 25: 0.143876, 26: 0.14309080000000002, 27: 0.14177940000000003, 28: 0.1401986, 29: 0.1399448, 30: 0.13810660000000002, 31: 0.13666240000000002, 32: 0.1354844, 33: 0.1339054, 34: 0.1302158, 35: 0.13022019999999998, 36: 0.127982, 37: 0.12693340000000003, 38: 0.1254906, 39: 0.12311679999999998, 40: 0.12272279999999999, 41: 0.12035119999999999, 42: 0.11956359999999999, 43: 0.11851039999999999, 44: 0.1174582, 45: 0.11587699999999998, 46: 0.1146906, 47: 0.1135062, 48: 0.1123186, 49: 0.1119278, 50: 0.11140019999999999, 51: 0.1098214, 52: 0.10942700000000001, 53: 0.107581, 54: 0.10771660000000001, 55: 0.1066622, 56: 0.1053434, 57: 0.1049468, 58: 0.104288, 59: 0.1028354, 60: 0.1025738, 61: 0.10231279999999998, 62: 0.1021832, 63: 0.102581, 64: 0.10165900000000001, 65: 0.10007379999999999, 66: 0.0998124, 67: 0.0988896, 68: 0.0992892, 69: 0.098498, 70: 0.0971756, 71: 0.0966482, 72: 0.0961206, 73: 0.09572639999999999, 74: 0.0951986, 75: 0.093876, 76: 0.0941416, 77: 0.0933504, 78: 0.0937484, 79: 0.0933552, 80: 0.09401820000000001, 81: 0.09335940000000001, 82: 0.0926984, 83: 0.0921724, 84: 0.09230659999999999, 85: 0.09138199999999999, 86: 0.09032480000000001, 87: 0.0901948, 88: 0.08966719999999999, 89: 0.0904628, 90: 0.08966959999999999, 91: 0.08900920000000001, 92: 0.0882152, 93: 0.088216, 94: 0.0880856, 95: 0.08769020000000001, 96: 0.0874258, 97: 0.08729659999999999, 98: 0.0870344, 99: 0.08716719999999999, 100: 0.08677140000000001, 101: 0.0863758, 102: 0.0863766, 103: 0.08584739999999999, 104: 0.0857164, 105: 0.08439379999999999, 106: 0.0837332, 107: 0.0841314, 108: 0.0840002, 109: 0.0840024, 110: 0.083606, 111: 0.084136, 112: 0.0842694, 113: 0.08479980000000001, 114: 0.0840066, 115: 0.0842732, 116: 0.0833472, 117: 0.08281780000000001, 118: 0.08202519999999999, 119: 0.082025, 120: 0.0818942, 121: 0.08163000000000001, 122: 0.0818962, 123: 0.0816322, 124: 0.0813692, 125: 0.081634, 126: 0.08057560000000001, 127: 0.0812388, 128: 0.0811072, 129: 0.0811072, 130: 0.080711, 131: 0.08097639999999999, 132: 0.0805794, 133: 0.0812422, 134: 0.08097839999999999, 135: 0.08150779999999999}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=59, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 4:  {'num_boost_round': 599, 'learning_rate': 0.09995848838749884, 'num_class': 2, 'objective': 'multi:softprob', 'max_depth': 27, 'min_child_weight': 0.696828678458152, 'subsample': 0.9790743055545253, 'colsample_bytree': 0.7195508901942145, 'gamma': 0.028255537498014956}\n",
      "\n",
      "\n",
      "\n",
      "====== Final Optimal Parameters ======\n",
      "{'num_boost_round': 599, 'learning_rate': 0.09995848838749884, 'num_class': 2, 'objective': 'multi:softprob', 'max_depth': 27, 'min_child_weight': 0.696828678458152, 'subsample': 0.9790743055545253, 'colsample_bytree': 0.7195508901942145, 'gamma': 0.028255537498014956}\n"
     ]
    }
   ],
   "source": [
    "eval_metric = fbeta_eval\n",
    "db_url = './xgboost.db'\n",
    "\n",
    "params = stepwise_optimisation(X_train, y_train, 2, eval_metric, db_url, n_jobs=1, trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b5cd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=params['num_boost_round'],\n",
    "    #obj='multi:softprob',\n",
    "    custom_metric=eval_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98a7e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Classification Report --------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      9721\n",
      "        True       0.45      0.02      0.04      1960\n",
      "\n",
      "    accuracy                           0.83     11681\n",
      "   macro avg       0.64      0.51      0.47     11681\n",
      "weighted avg       0.77      0.83      0.76     11681\n",
      "\n",
      "\n",
      "\n",
      "---------------- Confusion Matrix ----------------\n",
      "[[9673 1920]\n",
      " [  48   40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def classification_summary(y_pred: np.array, y_true: np.array):\n",
    "    \"\"\"\n",
    "    Prints a summary of classification results.\n",
    "\n",
    "    Params:\n",
    "        np.array: y_pred - predictions on y_test\n",
    "        np.array: y_true - actual test data, i.e. y_test\n",
    "\n",
    "    returns:\n",
    "        nothing \n",
    "    \"\"\"\n",
    "    print('\\n-------------- Classification Report --------------')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    print('\\n\\n---------------- Confusion Matrix ----------------')\n",
    "    print(confusion_matrix(y_preds, y_true))\n",
    "\n",
    "y_preds = model.predict(xgb.DMatrix(X_test, y_test, enable_categorical=True))\n",
    "y_preds = np.argmax(y_preds, axis=1)\n",
    "\n",
    "classification_summary(y_preds, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
